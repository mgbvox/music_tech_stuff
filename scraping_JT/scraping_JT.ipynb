{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "m9O35Ts5yjam",
    "outputId": "346337d5-eca8-43c4-9426-8c6062e464a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgbvox/anaconda3/envs/data_science/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['dist', 'text', 'mat', 'datetime', 'split']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "#requests for fetching html of website\n",
    "import requests\n",
    "\n",
    "# Make the request to a url\n",
    "r = requests.get('https://thejerseytenors.com/dates/')\n",
    "# Create soup from content of request\n",
    "c = r.content\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(c)\n",
    "\n",
    "import calendar\n",
    "cal = {v: k for k,v in enumerate(calendar.month_name)}\n",
    "\n",
    "import datetime\n",
    "import dateparser\n",
    "from dateparser import parse\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOzKJUUvzNcW"
   },
   "outputs": [],
   "source": [
    "# Find the element on the webpage\n",
    "main_content = soup.find_all('strong')\n",
    "text = [i.text for i in main_content]\n",
    "split = [i.split('â€“') for i in text]\n",
    "cleaned = [[''.join(filter(lambda x: x in string.printable, s)).strip() for s in l] for l in split]\n",
    "df = pd.DataFrame.from_records(cleaned, columns=('Date', 'City/State', 'INFO1', 'INFO2', 'INFO3'))\n",
    "dates = df['Date'].values\n",
    "df['Date'] = [parse(d) for d in dates]\n",
    "tour = df[(df.Date > parse('Feb 27th 2019')) & (df.Date < parse('April 11th 2019'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IUFbRoitcbBe"
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(timeout=10, user_agent = \"mgbvox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "biWEh8tCiihh"
   },
   "outputs": [],
   "source": [
    "cities = tour['City/State'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "A1xfeX8BfYP7",
    "outputId": "7ef002db-1eb4-4b49-9347-2e04ed828073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\r"
     ]
    }
   ],
   "source": [
    "to_examine = []\n",
    "locations = {}\n",
    "counter = 0\n",
    "for city in cities:\n",
    "    location = geolocator.geocode(city)\n",
    "    locations[city] = location\n",
    "    print(counter, end='\\r')\n",
    "    if location == None:\n",
    "        to_examine.append(city)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cities_df = pd.read_csv('census_cities.csv', encoding = \"ISO-8859-1\")\n",
    "cities_df = cities_df[['Geography', 'Population Estimate (as of July 1) - 2017']]\n",
    "\n",
    "cities_full = []\n",
    "short_to_full = {}\n",
    "for c in cities:\n",
    "    try:\n",
    "        c_split = c.split(' ')\n",
    "        state = states[c_split[-1]]\n",
    "        cities_full.append(' '.join(c_split[:-1]+[state]))\n",
    "        short_to_full[c] = ' '.join(c_split[:-1]+[state])\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = {}\n",
    "for c in cities_full:\n",
    "    best_sim = 0\n",
    "    best_name = ''\n",
    "    best_idx = -1\n",
    "    for i,n in enumerate(cities_df['Geography'].values):\n",
    "        sim = similar(c,n)\n",
    "        if sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_name = n\n",
    "            best_idx = i\n",
    "            #print('updated for {} - {}'.format(c,n))\n",
    "    \n",
    "    populations[c] = cities_df['Population Estimate (as of July 1) - 2017'][best_idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d991d5db527344958610c5116f529d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gmaps\n",
    "import os\n",
    "gmaps_key = 'AIzaSyDEQiJWTHAai9jW5CVfA1-jhQLNv5BsUck'\n",
    "gmaps.configure(api_key=gmaps_key)\n",
    "\n",
    "lon_lat = []\n",
    "tour_cities = []\n",
    "for city in tour['City/State']:\n",
    "    loc = locations[city]\n",
    "    try:\n",
    "        lon = loc.longitude\n",
    "        lat = loc.latitude\n",
    "        if lon < -90:\n",
    "            lon_lat.append((lat,lon))\n",
    "            tour_cities.append(short_to_full[city])\n",
    "    except:\n",
    "        pass\n",
    "   \n",
    "fig = gmaps.figure()\n",
    "\n",
    "# load a Numpy array of (latitude, longitude) pairs\n",
    "lon_lat = np.array(lon_lat)\n",
    "max_pop = np.max(list(populations.values()))\n",
    "\n",
    "for idx, ll in enumerate(lon_lat):\n",
    "    city_name = tour_cities[idx]\n",
    "    pop = populations[city_name]\n",
    "    scale = int((pop/max_pop)*10)+1\n",
    "    \n",
    "    city_point = gmaps.symbol_layer(\n",
    "        np.array([ll]), hover_text=city_name ,fill_color=\"green\", stroke_color=\"green\", scale=4)\n",
    "    fig.add_layer(city_point)\n",
    "\n",
    "#Gen Route:\n",
    "lines = []\n",
    "n_cities = len(lon_lat)\n",
    "incr = 255//n_cities\n",
    "for i in range(n_cities-1):\n",
    "    curr_pt = lon_lat[i]\n",
    "    next_pt = lon_lat[i+1]\n",
    "    lines.append(gmaps.Line(start=curr_pt,end=next_pt,\n",
    "                            stroke_weight=3.0,stroke_color=(0+(incr*i),255-(incr*i),100)))\n",
    "drawing = gmaps.drawing_layer(features=lines)\n",
    "fig.add_layer(drawing)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b206564d9d6429ca722405a599972f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tsp\n",
    "\n",
    "#Route Optimizer\n",
    "t = tsp.tsp(lon_lat)\n",
    "tsp_route = np.array(sorted(list(zip(t[1], lon_lat))))[:,1]\n",
    "\n",
    "#Plot optimized route!\n",
    "fig_tsp = gmaps.figure()\n",
    "\n",
    "for idx, ll in enumerate(tsp_route):\n",
    "    \n",
    "    city_point = gmaps.symbol_layer(\n",
    "        np.array([ll]),fill_color=\"green\", stroke_color=\"green\", scale=4)\n",
    "    fig_tsp.add_layer(city_point)\n",
    "\n",
    "#Gen Route:\n",
    "lines = []\n",
    "n_cities = len(tsp_route)\n",
    "incr = 255//n_cities\n",
    "for i in range(n_cities-1):\n",
    "    curr_pt = tsp_route[i]\n",
    "    next_pt = tsp_route[i+1]\n",
    "    lines.append(gmaps.Line(start=curr_pt,end=next_pt,\n",
    "                            stroke_weight=3.0,stroke_color=(0+(incr*i),255-(incr*i),100)))\n",
    "drawing = gmaps.drawing_layer(features=lines)\n",
    "fig_tsp.add_layer(drawing)\n",
    "\n",
    "fig_tsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  38.8368777, -107.8568294])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "scraping_JT.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
